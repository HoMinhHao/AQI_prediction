{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63461877-4b72-49ca-b34a-9dd76e9e1481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 15:45:06.914349: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 15:45:06.914391: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 15:45:06.914412: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 15:45:06.921866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 15:45:09.876624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:45:09.876850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:45:09.921927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:45:09.922721: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:45:09.922935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:45:09.923105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d46e8e-f200-4522-bdbb-fd001a355bbb",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33e68a5-4ed7-4b22-b172-668168b63c42",
   "metadata": {
    "id": "6Hmy8ZCTh8Nf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428fc6e4-641d-41b8-8981-27c73dc7ee07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyWavelets in /home/jupyter-iec_haoquy/.local/lib/python3.10/site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/tljh/user/lib/python3.10/site-packages (from PyWavelets) (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de33db4-c46d-4b0a-bd89-7ef28854ef1a",
   "metadata": {
    "id": "Q7vrQRyHvpmQ"
   },
   "outputs": [],
   "source": [
    "def read_data_csv(data_path):\n",
    "    df=pd.read_csv(data_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c36a58-d243-4cce-9d59-a6865788e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].interpolate()\n",
    "\n",
    "    df.fillna(method='ffill',inplace=True)\n",
    "    df.fillna(method='bfill',inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71189f01-9057-49f5-ac71-e2941b128fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_column(df,column_split,target):\n",
    "    X_train_df=pd.DataFrame()\n",
    "    X_test_df=pd.DataFrame()\n",
    "    \n",
    "    for city in df[column_split].unique():\n",
    "      df_temp=df.loc[df[column_split]==city]\n",
    "      threshold=int(df_temp.shape[0]*0.8)\n",
    "    \n",
    "      train_temp=df_temp[:threshold]\n",
    "      test_temp=df_temp[threshold:]\n",
    "    \n",
    "      X_train_df=pd.concat([X_train_df,train_temp],axis=0)\n",
    "      X_test_df=pd.concat([X_test_df,test_temp],axis=0)\n",
    "    \n",
    "    y_train_df=X_train_df[target].values\n",
    "    y_test_df=X_test_df[target].values\n",
    "    \n",
    "    X_train_df.set_index((i for i in range(len(X_train_df))),inplace=True)\n",
    "    X_test_df.set_index((i for i in range(len(X_test_df))),inplace=True)\n",
    "    \n",
    "    X_train_df.drop([target],axis=1,inplace=True)\n",
    "    X_test_df.drop([target],axis=1,inplace=True)\n",
    "    return X_train_df, y_train_df, X_test_df, y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6751fa3f-1346-4c67-8f4d-ffd3880c24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df,column):\n",
    "    label_encoder = preprocessing.LabelEncoder()    \n",
    "    # Encode labels in column 'species'. \n",
    "    df[column]= label_encoder.fit_transform(df[column]) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1df54d3-6c95-4f83-a742-008622b7bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values_percent(df):\n",
    "    for col in df.columns:\n",
    "      num_of_nan = df[col].isna().sum()\n",
    "      percent_of_nan=num_of_nan*100/len(df)\n",
    "      print(f\"Column \\\"{col}\\\" has {num_of_nan} missing values ({percent_of_nan}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5799bf-e88c-468a-93f5-b20ecf7f548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Scale dữ liệu về đoạn 0-1\n",
    "def scale_data(df_train,df_test,list_scale_features):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    values_train=df_train[list_scale_features].values\n",
    "    scaled_values_train = scaler.fit_transform(values_train)\n",
    "    df_train[list_scale_features]=scaled_values_train \n",
    "    \n",
    "    values_test=df_test[list_scale_features].values\n",
    "    scaled_values_test = scaler.transform(values_test)\n",
    "    df_test[list_scale_features]=scaled_values_test\n",
    "\n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2a3b6a-b4c7-48fd-9059-0d0fbef7196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_decomposition(data, wavelet_type='db1'):\n",
    "    return pywt.wavedec(data, wavelet_type, mode='per')\n",
    "\n",
    "def wavelet_reconstruction(coeffs, wavelet_type='db1'):\n",
    "    return pywt.waverec(coeffs, wavelet_type, mode='per')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1e65c2-6a32-4777-9d9b-cbbf066cc0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset):\n",
    "    global look_back\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        dataX.append(dataset[i:(i + look_back), 0])\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec044560-6e83-4fdf-a769-8cb3d5d81d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_slide(train,label):\n",
    "  #drop dữ liệu dư\n",
    "  window_size = 24\n",
    "  X = []\n",
    "  Y = []\n",
    "  label_index=window_size-1\n",
    "  for city in train['City'].unique():\n",
    "      df_city=train[train['City']==city]\n",
    "      for i in range(window_size, len(df_city)):\n",
    "        label_index+=1\n",
    "        X.append(df_city.iloc[i-window_size:i,:].values)\n",
    "        Y.append(label[label_index,:])\n",
    "  return np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c8b39fe-5e5b-4bea-be74-4400970a5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_autoencoder_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units = 64,activation='relu'), input_shape=(X_train_wt.shape[1], X_train_wt.shape[-1])))\n",
    "    model.add(RepeatVector(input_shape[0]))\n",
    "    model.add(Bidirectional(LSTM(units = 64, activation='relu',return_sequences=True)))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab7bcbcc-6971-4c26-80ce-c577ace5e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_attention_model(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    lstm1=Bidirectional(LSTM(units = 64,activation='relu',return_sequences=True))(input)\n",
    "    lstm_output=Bidirectional(LSTM(units = 32, activation='relu',return_sequences=True))(lstm1)\n",
    "    # Attention mechanism\n",
    "    attention_output = Attention()([lstm_output, lstm_output])\n",
    "    # Concatenate LSTM output and attention output\n",
    "    combined_output = Concatenate()([lstm_output, attention_output])\n",
    "    # Additional layers if needed\n",
    "    output = Dense(1)(combined_output)\n",
    "    model = Model(inputs=[input], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f548bfb0-4e30-4df5-a879-6d5b5997e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train,y_train,lr=0.001,epochs=10,batch_size=64):\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de02a754-5d31-4925-9a10-047a1d0e7046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>1/1/2015 1:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.01</td>\n",
       "      <td>36.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>122.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>1/1/2015 2:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>27.75</td>\n",
       "      <td>19.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>85.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>1/1/2015 3:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>19.32</td>\n",
       "      <td>11.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>52.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>1/1/2015 4:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>16.45</td>\n",
       "      <td>9.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>39.53</td>\n",
       "      <td>153.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>1/1/2015 5:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>14.90</td>\n",
       "      <td>7.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>32.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City       Datetime  PM2.5  PM10    NO    NO2    NOx  NH3    CO  \\\n",
       "0  Ahmedabad  1/1/2015 1:00    NaN   NaN  1.00  40.01  36.37  NaN  1.00   \n",
       "1  Ahmedabad  1/1/2015 2:00    NaN   NaN  0.02  27.75  19.73  NaN  0.02   \n",
       "2  Ahmedabad  1/1/2015 3:00    NaN   NaN  0.08  19.32  11.08  NaN  0.08   \n",
       "3  Ahmedabad  1/1/2015 4:00    NaN   NaN  0.30  16.45   9.20  NaN  0.30   \n",
       "4  Ahmedabad  1/1/2015 5:00    NaN   NaN  0.12  14.90   7.85  NaN  0.12   \n",
       "\n",
       "      SO2      O3  Benzene  Toluene  Xylene  AQI AQI_Bucket Country  \n",
       "0  122.07     NaN      0.0      0.0     0.0  NaN        NaN   India  \n",
       "1   85.90     NaN      0.0      0.0     0.0  NaN        NaN   India  \n",
       "2   52.83     NaN      0.0      0.0     0.0  NaN        NaN   India  \n",
       "3   39.53  153.58      0.0      0.0     0.0  NaN        NaN   India  \n",
       "4   32.63     NaN      0.0      0.0     0.0  NaN        NaN   India  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read dataset\n",
    "df=read_data_csv('India_dataset_raw.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35fc39-0699-4121-906f-98118cb05cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kiểm tra xem bao nhiêu phần trăm dữ liệu bị thiếu của mỗi feature trong từng thành phố\n",
    "for i in df['City'].unique():\n",
    "    temp=df[df['City']==i]\n",
    "    print(f'{i}:\\n{(temp.isna().sum()/len(temp))*100}\\n') #Đơn vị phần trăm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10331e93-9066-4892-b8eb-e7518abd89a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48192</th>\n",
       "      <td>Aizawl</td>\n",
       "      <td>42.00</td>\n",
       "      <td>51.28</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.66</td>\n",
       "      <td>19.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>3.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48193</th>\n",
       "      <td>Aizawl</td>\n",
       "      <td>41.17</td>\n",
       "      <td>49.96</td>\n",
       "      <td>4.51</td>\n",
       "      <td>1.27</td>\n",
       "      <td>7.24</td>\n",
       "      <td>21.55</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48194</th>\n",
       "      <td>Aizawl</td>\n",
       "      <td>24.97</td>\n",
       "      <td>42.04</td>\n",
       "      <td>7.25</td>\n",
       "      <td>5.45</td>\n",
       "      <td>14.56</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.93</td>\n",
       "      <td>6.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48195</th>\n",
       "      <td>Aizawl</td>\n",
       "      <td>26.95</td>\n",
       "      <td>38.86</td>\n",
       "      <td>7.31</td>\n",
       "      <td>2.52</td>\n",
       "      <td>12.13</td>\n",
       "      <td>21.94</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48196</th>\n",
       "      <td>Aizawl</td>\n",
       "      <td>17.42</td>\n",
       "      <td>37.15</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1.58</td>\n",
       "      <td>11.14</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  PM2.5   PM10    NO   NO2    NOx    NH3    CO   SO2    O3  AQI\n",
       "48192  Aizawl  42.00  51.28  4.27  0.97   6.66  19.88  0.37  3.35   NaN  NaN\n",
       "48193  Aizawl  41.17  49.96  4.51  1.27   7.24  21.55  0.38  3.44   NaN  NaN\n",
       "48194  Aizawl  24.97  42.04  7.25  5.45  14.56  20.25  0.50  3.93  6.95  NaN\n",
       "48195  Aizawl  26.95  38.86  7.31  2.52  12.13  21.94  0.52  3.93   NaN  NaN\n",
       "48196  Aizawl  17.42  37.15  7.25  1.58  11.14  25.71  0.49  4.36   NaN  NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop những thành phố có tỉ lệ missing value cao\n",
    "for city in ['Ahmedabad','Patna','Lucknow','Jorapokhar','Gurugram','Chennai']:\n",
    "    df.drop(df.index[df['City']==city],inplace=True)\n",
    "\n",
    "#Drop những feature không liên quan đến chỉ số AQI\n",
    "df = df.drop(['Country','AQI_Bucket','Benzene','Toluene','Xylene','Datetime'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63e73f9d-bbfb-4a21-937f-c1c5f80a75e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1179928/3008641224.py:3: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df[column] = df[column].interpolate()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column \"City\" has 0 missing values (0.0%)\n",
      "Column \"PM2.5\" has 0 missing values (0.0%)\n",
      "Column \"PM10\" has 0 missing values (0.0%)\n",
      "Column \"NO\" has 0 missing values (0.0%)\n",
      "Column \"NO2\" has 0 missing values (0.0%)\n",
      "Column \"NOx\" has 0 missing values (0.0%)\n",
      "Column \"NH3\" has 0 missing values (0.0%)\n",
      "Column \"CO\" has 0 missing values (0.0%)\n",
      "Column \"SO2\" has 0 missing values (0.0%)\n",
      "Column \"O3\" has 0 missing values (0.0%)\n",
      "Column \"AQI\" has 0 missing values (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1179928/3008641224.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill',inplace=True)\n",
      "/tmp/ipykernel_1179928/3008641224.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Fill missing value\n",
    "df=fill_missing_values(df)\n",
    "    \n",
    "#Kiểm tra lại số missing value   \n",
    "check_missing_values_percent(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1ab6a23-cf9b-43ef-a938-7ecc4f956e90",
   "metadata": {
    "id": "0tt0PA0fzEuh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of X train city:  20\n",
      "Number of X test city:  20\n",
      "X train:  (360361, 10)\n",
      "y train:  (360361,)\n",
      "X test:  (90101, 10)\n",
      "y test:  (90101,)\n"
     ]
    }
   ],
   "source": [
    "#Tách dữ liệu thành tập train và test\n",
    "X_train_df, y_train_df, X_test_df, y_test_df=train_test_split_by_column(df,'City','AQI')\n",
    "print('Number of X train city: ',X_train_df['City'].nunique())\n",
    "print('Number of X test city: ',X_test_df['City'].nunique())\n",
    "print('X train: ',X_train_df.shape)\n",
    "print('y train: ',y_train_df.shape)\n",
    "print('X test: ',X_test_df.shape)\n",
    "print('y test: ',y_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf35624b-fa5b-4cc1-ba05-705332681df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>51.28</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.66</td>\n",
       "      <td>19.88</td>\n",
       "      <td>0.37</td>\n",
       "      <td>3.35</td>\n",
       "      <td>6.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>41.17</td>\n",
       "      <td>49.96</td>\n",
       "      <td>4.51</td>\n",
       "      <td>1.27</td>\n",
       "      <td>7.24</td>\n",
       "      <td>21.55</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24.97</td>\n",
       "      <td>42.04</td>\n",
       "      <td>7.25</td>\n",
       "      <td>5.45</td>\n",
       "      <td>14.56</td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.93</td>\n",
       "      <td>6.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>26.95</td>\n",
       "      <td>38.86</td>\n",
       "      <td>7.31</td>\n",
       "      <td>2.52</td>\n",
       "      <td>12.13</td>\n",
       "      <td>21.94</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.93</td>\n",
       "      <td>5.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17.42</td>\n",
       "      <td>37.15</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1.58</td>\n",
       "      <td>11.14</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360356</th>\n",
       "      <td>19</td>\n",
       "      <td>42.75</td>\n",
       "      <td>116.00</td>\n",
       "      <td>13.72</td>\n",
       "      <td>43.15</td>\n",
       "      <td>34.10</td>\n",
       "      <td>4.62</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.55</td>\n",
       "      <td>31.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360357</th>\n",
       "      <td>19</td>\n",
       "      <td>43.00</td>\n",
       "      <td>127.00</td>\n",
       "      <td>23.23</td>\n",
       "      <td>58.55</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.12</td>\n",
       "      <td>9.50</td>\n",
       "      <td>18.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360358</th>\n",
       "      <td>19</td>\n",
       "      <td>39.50</td>\n",
       "      <td>138.50</td>\n",
       "      <td>34.90</td>\n",
       "      <td>57.93</td>\n",
       "      <td>59.17</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.01</td>\n",
       "      <td>11.07</td>\n",
       "      <td>14.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360359</th>\n",
       "      <td>19</td>\n",
       "      <td>33.00</td>\n",
       "      <td>117.00</td>\n",
       "      <td>41.33</td>\n",
       "      <td>52.92</td>\n",
       "      <td>61.73</td>\n",
       "      <td>3.72</td>\n",
       "      <td>2.67</td>\n",
       "      <td>11.73</td>\n",
       "      <td>12.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360360</th>\n",
       "      <td>19</td>\n",
       "      <td>37.00</td>\n",
       "      <td>131.75</td>\n",
       "      <td>29.95</td>\n",
       "      <td>47.55</td>\n",
       "      <td>49.65</td>\n",
       "      <td>3.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>11.28</td>\n",
       "      <td>11.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360361 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        City  PM2.5    PM10     NO    NO2    NOx    NH3    CO    SO2       O3\n",
       "0          0  42.00   51.28   4.27   0.97   6.66  19.88  0.37   3.35   6.9500\n",
       "1          0  41.17   49.96   4.51   1.27   7.24  21.55  0.38   3.44   6.9500\n",
       "2          0  24.97   42.04   7.25   5.45  14.56  20.25  0.50   3.93   6.9500\n",
       "3          0  26.95   38.86   7.31   2.52  12.13  21.94  0.52   3.93   5.7975\n",
       "4          0  17.42   37.15   7.25   1.58  11.14  25.71  0.49   4.36   4.6450\n",
       "...      ...    ...     ...    ...    ...    ...    ...   ...    ...      ...\n",
       "360356    19  42.75  116.00  13.72  43.15  34.10   4.62  1.98   5.55  31.8200\n",
       "360357    19  43.00  127.00  23.23  58.55  50.00   4.10  2.12   9.50  18.6200\n",
       "360358    19  39.50  138.50  34.90  57.93  59.17   3.70  2.01  11.07  14.0700\n",
       "360359    19  33.00  117.00  41.33  52.92  61.73   3.72  2.67  11.73  12.6000\n",
       "360360    19  37.00  131.75  29.95  47.55  49.65   3.98  0.93  11.28  11.5000\n",
       "\n",
       "[360361 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_new=label_encoding(X_train_df,'City')\n",
    "df_test_new=label_encoding(X_test_df,'City')\n",
    "df_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90884624-a6ff-4195-a978-48784ceeede9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.041991</td>\n",
       "      <td>0.051271</td>\n",
       "      <td>0.008538</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.013462</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.016707</td>\n",
       "      <td>0.013947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.041161</td>\n",
       "      <td>0.049950</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.044338</td>\n",
       "      <td>0.007606</td>\n",
       "      <td>0.017157</td>\n",
       "      <td>0.013947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>0.042030</td>\n",
       "      <td>0.014510</td>\n",
       "      <td>0.010891</td>\n",
       "      <td>0.029430</td>\n",
       "      <td>0.041662</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.013947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>0.014630</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.024518</td>\n",
       "      <td>0.045141</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.011631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017410</td>\n",
       "      <td>0.037140</td>\n",
       "      <td>0.014510</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>0.052901</td>\n",
       "      <td>0.009808</td>\n",
       "      <td>0.021759</td>\n",
       "      <td>0.009315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City     PM2.5      PM10        NO       NO2       NOx       NH3        CO  \\\n",
       "0     0  0.041991  0.051271  0.008538  0.001922  0.013462  0.040901  0.007406   \n",
       "1     0  0.041161  0.049950  0.009019  0.002523  0.014634  0.044338  0.007606   \n",
       "2     0  0.024960  0.042030  0.014510  0.010891  0.029430  0.041662  0.010008   \n",
       "3     0  0.026941  0.038850  0.014630  0.005025  0.024518  0.045141  0.010408   \n",
       "4     0  0.017410  0.037140  0.014510  0.003143  0.022517  0.052901  0.009808   \n",
       "\n",
       "        SO2        O3  \n",
       "0  0.016707  0.013947  \n",
       "1  0.017157  0.013947  \n",
       "2  0.019608  0.013947  \n",
       "3  0.019608  0.011631  \n",
       "4  0.021759  0.009315  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features=['PM2.5','PM10','SO2','CO','O3','NO','NO2','NOx','NH3']\n",
    "df_train_scaled,df_test_scaled=scale_data(df_train_new,df_test_new,scaled_features)\n",
    "df_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76296e59-43e1-401b-9a24-4b5c101d652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y train (359881, 1)\n",
      "X train (359881, 24, 10)\n",
      "Y test (89621, 1)\n",
      "X test (89621, 24, 10)\n"
     ]
    }
   ],
   "source": [
    "#Chia dữ liệu thành các frame\n",
    "y_train=np.reshape(y_train_df,(len(y_train_df),1))\n",
    "y_test=np.reshape(y_test_df,(len(y_test_df),1))\n",
    "\n",
    "X_train,y_train=window_slide(df_train_new,y_train)\n",
    "print('Y train' ,y_train.shape)\n",
    "print('X train' ,X_train.shape)\n",
    "\n",
    "X_test,y_test=window_slide(df_test_new,y_test)\n",
    "print('Y test' ,y_test.shape)\n",
    "print('X test' ,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4db7c152-bbfe-4974-a4d7-5700a5a631cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 15:46:06.312293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:46:06.312601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:46:06.312809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:46:06.448035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:46:06.448279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:46:06.448468: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-11-09 15:46:06.448516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-09 15:46:06.448692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10396 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:09:00.0, compute capability: 8.6\n",
      "2023-11-09 15:46:06.558088: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 15:46:12.820987: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f70740805e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-09 15:46:12.821010: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-11-09 15:46:12.824589: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-09 15:46:12.866879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2023-11-09 15:46:12.953789: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 555/5624 [=>............................] - ETA: 9:11 - loss: 4118774.2500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m=\u001b[39mbuild_lstm_attention_model((X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 16\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Main model\n",
    "from numpy import array\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Bidirectional\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector,Dropout\n",
    "from keras.layers import TimeDistributed,BatchNormalization, Input,Attention,Concatenate\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.models import Model\n",
    "import torch\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model=build_lstm_autoencoder_model((X_train.shape[1], X_train.shape[-1]))\n",
    "model=train_model([X_train], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff023067-c5c6-4e79-98b6-8e962faa594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'wt_attention.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2cae4-9da2-449b-abf1-b66b11c2ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # filename = 'finalized_model.sav'\n",
    "# # model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# filename = 'wt_attention.sav'\n",
    "# model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c5cb7-6598-487a-acc9-c02226142712",
   "metadata": {
    "id": "ulDuSwVzfqs9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred=model.predict(X_test_wt)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('MSE: ',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf8704c-63b6-4369-95e8-5fed0cd7071e",
   "metadata": {
    "id": "ia7jlD4KI0OS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot the graph between actual vs predicted values\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(y_pred[:1000,:], color= 'green',label = 'Predicted AQI')\n",
    "plt.plot(y_test[:1000,:] , color = 'red',label = 'Actual AQI')\n",
    "plt.title(\"AQI Prediction (Multivariate)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"AQI\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('graph.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
